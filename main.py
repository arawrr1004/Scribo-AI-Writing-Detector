import uvicorn
from fastapi import FastAPI
from pydantic import BaseModel
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

# 1. Buat Aplikasi Backend
app = FastAPI(title="AI Writing Detector")

# 2. Membuat Model AI Sederhana (Agar langsung bisa jalan tanpa download file luar)
# Data latihan: 0 = Manusia, 1 = AI
texts = [
    "Saya tadi pagi makan nasi goreng enak sekali.", 
    "Hari ini cuaca sangat cerah untuk jalan-jalan.", 
    "As an AI language model, I provide helpful information.", 
    "This content was generated by a large language model."
]
labels = [0, 0, 1, 1]

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(texts)
model = LogisticRegression()
model.fit(X, labels)

# 3. Setting Input Data
class InputTeks(BaseModel):
    teks: str

# 4. Halaman Utama (Biar tahu kalau aplikasinya nyala)
@app.get("/")
def home():
    return {"status": "Berhasil!", "pesan": "Backend AI sudah aktif. Buka /docs untuk tes."}

# 5. Fungsi Deteksi AI
@app.post("/predict")
def predict(data: InputTeks):
    vektor = vectorizer.transform([data.teks])
    probabilitas = model.predict_proba(vektor)[0]
    skor_ai = float(probabilitas[1]) 

    # Logika Tiga Kategori agar user tidak bingung dengan angka 49%
    if skor_ai > 0.75:
        hasil = "AI Detected"
    elif skor_ai > 0.60:
        hasil = "Possibly AI Generated" # Ini untuk angka seperti 49% tadi
    else:
        hasil = "Likely Human Written"
 
    
    # TAMPILKAN DI CMD LAPTOP UNTUK CEK
    print(f"DEBUG SKOR DARI MODEL: {skor_ai}")
    
        
    # PASTIKAN KEY-NYA BERNAMA "skor" (huruf kecil semua)
    return {
        "hasil": hasil,
        "skor": skor_ai,
        "teks_asli": data.teks
    }
# 6. Jalankan Server
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)